wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: mingyulu (data_att) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /data/mingyulu/wandb/wandb/run-20260203_174833-mcc8zefi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-universe-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/data_att/Convergence%20for%20Shapley%20value%20sprint
wandb: üöÄ View run at https://wandb.ai/data_att/Convergence%20for%20Shapley%20value%20sprint/runs/mcc8zefi
Namespace(num_trials=30, cohort_name='sprint', baseline=False, wandb=True, relative_change_threshold=0.05, top_n_features=15, device='cuda:2')
Using device: cuda:2
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.834568440914154, train_loss: 0.8360753059387207
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2676416337490082, train_loss: 0.22939050197601318
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2426481693983078, train_loss: 0.1762448102235794
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24288581311702728, train_loss: 0.16819798946380615
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24316450953483582, train_loss: 0.1649586260318756
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6377494931221008, train_loss: 0.6428605318069458
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22846044600009918, train_loss: 0.1957891434431076
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21510162949562073, train_loss: 0.15609578788280487
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21513022482395172, train_loss: 0.15298382937908173
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21547119319438934, train_loss: 0.14997363090515137
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6290265321731567, train_loss: 0.6384080052375793
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27078062295913696, train_loss: 0.22917379438877106
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.26405301690101624, train_loss: 0.1899012327194214
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26457327604293823, train_loss: 0.18456633388996124
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26530468463897705, train_loss: 0.17588888108730316
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6154367923736572, train_loss: 0.633999764919281
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23029384016990662, train_loss: 0.1622430384159088
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22316782176494598, train_loss: 0.1207733079791069
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22380034625530243, train_loss: 0.11844782531261444
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22495350241661072, train_loss: 0.11492113769054413
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.43978050351142883, train_loss: 0.5663928389549255
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08190008997917175, train_loss: 0.05754633620381355
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08019587397575378, train_loss: 0.04865562543272972
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07992508262395859, train_loss: 0.04481180012226105
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07993604987859726, train_loss: 0.0453290231525898
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2227540761232376, train_loss: 0.2975797653198242
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06520833820104599, train_loss: 0.04798099398612976
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06409648805856705, train_loss: 0.04099360480904579
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06407530605792999, train_loss: 0.03967335820198059
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06387578696012497, train_loss: 0.038550399243831635
Trial 1/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 156.44it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.29it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 245/2001 [00:01<00:10, 162.74it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 328/2001 [00:02<00:10, 163.54it/s]Shapley Value Sampling attribution:  21%|‚ñà‚ñà        | 411/2001 [00:02<00:09, 164.07it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 494/2001 [00:03<00:09, 164.47it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñâ       | 577/2001 [00:03<00:08, 164.81it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 660/2001 [00:04<00:08, 165.08it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 743/2001 [00:04<00:07, 165.15it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 826/2001 [00:05<00:07, 165.27it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 909/2001 [00:05<00:06, 165.27it/s]Shapley Value Sampling attribution:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 992/2001 [00:06<00:06, 165.36it/s]Shapley Value Sampling attribution:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1075/2001 [00:06<00:05, 165.39it/s]Shapley Value Sampling attribution:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1158/2001 [00:07<00:05, 165.29it/s]Shapley Value Sampling attribution:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1241/2001 [00:07<00:04, 165.11it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1324/2001 [00:08<00:04, 165.06it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1407/2001 [00:08<00:03, 165.01it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1490/2001 [00:09<00:03, 165.06it/s]Shapley Value Sampling attribution:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1573/2001 [00:09<00:02, 164.96it/s]Shapley Value Sampling attribution:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1656/2001 [00:10<00:02, 164.98it/s]Shapley Value Sampling attribution:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1739/2001 [00:10<00:01, 164.88it/s]Shapley Value Sampling attribution:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1822/2001 [00:11<00:01, 164.89it/s]Shapley Value Sampling attribution:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1905/2001 [00:11<00:00, 164.91it/s]Shapley Value Sampling attribution:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1988/2001 [00:12<00:00, 164.99it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 164.71it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8698038458824158, train_loss: 0.885735273361206
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2955893576145172, train_loss: 0.25059953331947327
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.27347108721733093, train_loss: 0.19209615886211395
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27409353852272034, train_loss: 0.18821509182453156
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27449852228164673, train_loss: 0.18587559461593628
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.661597728729248, train_loss: 0.673059344291687
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.20102274417877197, train_loss: 0.18140248954296112
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.17961643636226654, train_loss: 0.13457268476486206
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.17978772521018982, train_loss: 0.1291133463382721
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.17988480627536774, train_loss: 0.12598417699337006
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7370166182518005, train_loss: 0.769012451171875
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2587585747241974, train_loss: 0.22982805967330933
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23799863457679749, train_loss: 0.17461451888084412
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2380933165550232, train_loss: 0.16773195564746857
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23854199051856995, train_loss: 0.1694440096616745
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.62306147813797, train_loss: 0.6224335432052612
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2383631467819214, train_loss: 0.20269650220870972
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21990850567817688, train_loss: 0.15735220909118652
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21956989169120789, train_loss: 0.14694499969482422
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21982036530971527, train_loss: 0.14060983061790466
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.25371643900871277, train_loss: 0.3158808648586273
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07800576090812683, train_loss: 0.059975117444992065
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07663829624652863, train_loss: 0.04646550118923187
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07657197117805481, train_loss: 0.04676951467990875
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07664526998996735, train_loss: 0.04554390907287598
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4584581255912781, train_loss: 0.6058980226516724
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07853887975215912, train_loss: 0.04731658846139908
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.07590532302856445, train_loss: 0.038861971348524094
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.07574553042650223, train_loss: 0.03803062438964844
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07583390921354294, train_loss: 0.03664067015051842
Trial 2/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 157.78it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.72it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 162.73it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 163.21it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 163.47it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 163.49it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 163.50it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 163.47it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 163.52it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 163.62it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 163.69it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 163.72it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 163.74it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 163.66it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 163.70it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 163.75it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 163.57it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 163.61it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 163.60it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 163.57it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 163.49it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 163.57it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 163.55it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 163.51it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.44it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.4695296287536621, train_loss: 0.49434995651245117
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2475856989622116, train_loss: 0.21077987551689148
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.24828466773033142, train_loss: 0.19081513583660126
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2492179274559021, train_loss: 0.18495428562164307
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25049999356269836, train_loss: 0.1807059496641159
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5791890025138855, train_loss: 0.5955318212509155
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2588344216346741, train_loss: 0.1862155795097351
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2550770938396454, train_loss: 0.15442074835300446
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2558116912841797, train_loss: 0.14839398860931396
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2571064829826355, train_loss: 0.14542222023010254
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6938040852546692, train_loss: 0.7068907618522644
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27595651149749756, train_loss: 0.19273307919502258
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.27214956283569336, train_loss: 0.1629805862903595
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2732032239437103, train_loss: 0.1586335003376007
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2749452292919159, train_loss: 0.15341900289058685
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6808326840400696, train_loss: 0.6705477833747864
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2098587602376938, train_loss: 0.1992119997739792
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.1776941865682602, train_loss: 0.14313195645809174
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.17422454059123993, train_loss: 0.1292526125907898
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.1737031638622284, train_loss: 0.12336833029985428
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2472252994775772, train_loss: 0.3339649736881256
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07325075566768646, train_loss: 0.06030425429344177
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07084224373102188, train_loss: 0.05013327673077583
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07059930264949799, train_loss: 0.049389664083719254
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0704861730337143, train_loss: 0.04904014244675636
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.29715847969055176, train_loss: 0.38091495633125305
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07296715676784515, train_loss: 0.049358099699020386
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.0705631822347641, train_loss: 0.03764573112130165
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.0704956203699112, train_loss: 0.03714696690440178
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07057081907987595, train_loss: 0.03694997355341911
Trial 3/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.76it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.83it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 161.88it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 325/2001 [00:02<00:10, 162.40it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 407/2001 [00:02<00:09, 162.72it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 489/2001 [00:03<00:09, 162.79it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 571/2001 [00:03<00:08, 162.98it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 653/2001 [00:04<00:08, 163.10it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 735/2001 [00:04<00:07, 163.04it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 817/2001 [00:05<00:07, 163.12it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 899/2001 [00:05<00:06, 163.16it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 981/2001 [00:06<00:06, 163.10it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1063/2001 [00:06<00:05, 163.16it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1145/2001 [00:07<00:05, 163.20it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1227/2001 [00:07<00:04, 163.22it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1309/2001 [00:08<00:04, 163.23it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1391/2001 [00:08<00:03, 163.14it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1473/2001 [00:09<00:03, 163.19it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1555/2001 [00:09<00:02, 163.22it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1637/2001 [00:10<00:02, 163.07it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1719/2001 [00:10<00:01, 163.14it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1801/2001 [00:11<00:01, 163.05it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1883/2001 [00:11<00:00, 163.11it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1965/2001 [00:12<00:00, 162.91it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.88it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.48531025648117065, train_loss: 0.5105389356613159
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2553741931915283, train_loss: 0.20064495503902435
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.25075480341911316, train_loss: 0.17179052531719208
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2512452304363251, train_loss: 0.16770502924919128
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25180572271347046, train_loss: 0.16344882547855377
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5424101948738098, train_loss: 0.5498502254486084
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22458384931087494, train_loss: 0.19906575977802277
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20842313766479492, train_loss: 0.15620823204517365
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20873910188674927, train_loss: 0.15118840336799622
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20894254744052887, train_loss: 0.15249194204807281
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8808218836784363, train_loss: 0.8989235162734985
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27196529507637024, train_loss: 0.24497652053833008
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2490285038948059, train_loss: 0.19350099563598633
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2503878176212311, train_loss: 0.18131136894226074
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25097110867500305, train_loss: 0.17777019739151
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4834873378276825, train_loss: 0.500950276851654
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2019212394952774, train_loss: 0.17921848595142365
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18944191932678223, train_loss: 0.14131605625152588
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.1887572705745697, train_loss: 0.1331426054239273
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18866325914859772, train_loss: 0.13396230340003967
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3410632014274597, train_loss: 0.4406425654888153
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.089074045419693, train_loss: 0.05337250977754593
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08730540424585342, train_loss: 0.045690134167671204
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.087331123650074, train_loss: 0.04520392417907715
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08721984177827835, train_loss: 0.04380170255899429
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.1702127605676651, train_loss: 0.18218791484832764
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06584987789392471, train_loss: 0.04607280343770981
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06336203962564468, train_loss: 0.03708356246352196
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06332092732191086, train_loss: 0.03672589361667633
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06328301131725311, train_loss: 0.03650180250406265
Trial 4/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.41it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.55it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 160.80it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.40it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 405/2001 [00:02<00:09, 161.56it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 487/2001 [00:03<00:09, 161.84it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 568/2001 [00:03<00:08, 161.89it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 649/2001 [00:04<00:08, 161.89it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 731/2001 [00:04<00:07, 161.99it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 813/2001 [00:05<00:07, 162.10it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 895/2001 [00:05<00:06, 162.09it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 977/2001 [00:06<00:06, 162.12it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1059/2001 [00:06<00:05, 162.17it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1141/2001 [00:07<00:05, 161.98it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1223/2001 [00:07<00:04, 162.07it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1305/2001 [00:08<00:04, 162.00it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1387/2001 [00:08<00:03, 162.10it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1469/2001 [00:09<00:03, 162.03it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1551/2001 [00:09<00:02, 162.11it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1633/2001 [00:10<00:02, 161.99it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1715/2001 [00:10<00:01, 162.08it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1797/2001 [00:11<00:01, 162.16it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1879/2001 [00:11<00:00, 162.24it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1961/2001 [00:12<00:00, 162.25it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.88it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0148656368255615, train_loss: 1.03489351272583
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2732296884059906, train_loss: 0.25188568234443665
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2306695431470871, train_loss: 0.18366554379463196
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23057959973812103, train_loss: 0.1634577512741089
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2307833582162857, train_loss: 0.15869909524917603
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6683736443519592, train_loss: 0.6814175844192505
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22903619706630707, train_loss: 0.16928283870220184
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2173956334590912, train_loss: 0.12306161969900131
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21772728860378265, train_loss: 0.11516201496124268
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21860216557979584, train_loss: 0.1129956841468811
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.605243980884552, train_loss: 0.6139865517616272
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26340118050575256, train_loss: 0.22628596425056458
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.24815316498279572, train_loss: 0.18742363154888153
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24878625571727753, train_loss: 0.1768915057182312
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24913696944713593, train_loss: 0.175226092338562
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7435207366943359, train_loss: 0.7768791913986206
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22068528831005096, train_loss: 0.21441587805747986
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.19904786348342896, train_loss: 0.16705474257469177
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.19874101877212524, train_loss: 0.1528470516204834
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.19875985383987427, train_loss: 0.15312504768371582
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.21336451172828674, train_loss: 0.2772170305252075
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0686391070485115, train_loss: 0.059177398681640625
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.0664520412683487, train_loss: 0.04638751596212387
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.06652824580669403, train_loss: 0.04532502964138985
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.06654966622591019, train_loss: 0.044702090322971344
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.2072516679763794, train_loss: 1.39816153049469
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06679867953062057, train_loss: 0.04781048744916916
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06459273397922516, train_loss: 0.0381498709321022
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06454441696405411, train_loss: 0.03783460706472397
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06436685472726822, train_loss: 0.036139026284217834
Trial 5/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.16it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.77it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.11it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.75it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 161.92it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 487/2001 [00:03<00:09, 161.94it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 569/2001 [00:03<00:08, 162.16it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 651/2001 [00:04<00:08, 162.19it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 733/2001 [00:04<00:07, 162.35it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 815/2001 [00:05<00:07, 162.44it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 897/2001 [00:05<00:06, 162.25it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 979/2001 [00:06<00:06, 162.36it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1061/2001 [00:06<00:05, 162.47it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1143/2001 [00:07<00:05, 162.48it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1225/2001 [00:07<00:04, 162.42it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1307/2001 [00:08<00:04, 162.51it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1389/2001 [00:08<00:03, 162.45it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1471/2001 [00:09<00:03, 162.54it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1553/2001 [00:09<00:02, 162.57it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1635/2001 [00:10<00:02, 162.60it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1717/2001 [00:10<00:01, 162.62it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1799/2001 [00:11<00:01, 162.55it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1881/2001 [00:11<00:00, 162.58it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1963/2001 [00:12<00:00, 162.54it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.22it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0767886638641357, train_loss: 1.1013638973236084
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2978985905647278, train_loss: 0.2666269838809967
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2550019919872284, train_loss: 0.19315874576568604
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2550460994243622, train_loss: 0.18140417337417603
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2553230822086334, train_loss: 0.17793531715869904
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.43837347626686096, train_loss: 0.4684675633907318
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.1772538423538208, train_loss: 0.15920959413051605
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.17149418592453003, train_loss: 0.12763570249080658
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.1718365103006363, train_loss: 0.12251468747854233
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.17223051190376282, train_loss: 0.11968839168548584
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8442429304122925, train_loss: 0.8622138500213623
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.28088298439979553, train_loss: 0.23294031620025635
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.26009806990623474, train_loss: 0.17800171673297882
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2602887749671936, train_loss: 0.17565196752548218
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2607283294200897, train_loss: 0.17305181920528412
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.44839799404144287, train_loss: 0.4432222247123718
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.239597350358963, train_loss: 0.19147321581840515
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2404918223619461, train_loss: 0.16685855388641357
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2415531724691391, train_loss: 0.16664761304855347
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2427813708782196, train_loss: 0.16342681646347046
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2904881536960602, train_loss: 0.3800080418586731
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0831264778971672, train_loss: 0.05870218947529793
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08103479444980621, train_loss: 0.048191435635089874
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.0809611827135086, train_loss: 0.047583840787410736
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08079760521650314, train_loss: 0.04597332701086998
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41590893268585205, train_loss: 0.4973147213459015
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06596855819225311, train_loss: 0.04963225498795509
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06347358226776123, train_loss: 0.038421280682086945
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06342597305774689, train_loss: 0.03768354281783104
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06353428214788437, train_loss: 0.03716132789850235
Trial 6/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.06it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.79it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.19it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.86it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 162.18it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 162.33it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 162.50it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 162.57it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 162.62it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 162.70it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 162.56it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 162.60it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 162.68it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 162.75it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 162.68it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 162.65it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 162.72it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 162.72it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 162.76it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 162.66it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 162.73it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 162.76it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 162.73it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 162.75it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.41it/s]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.050938606262207, train_loss: 1.070267915725708
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27108654379844666, train_loss: 0.2599489986896515
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.21821710467338562, train_loss: 0.19484567642211914
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2124108076095581, train_loss: 0.16532237827777863
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.21292680501937866, train_loss: 0.1570117473602295
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7240742444992065, train_loss: 0.728827953338623
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2396029233932495, train_loss: 0.19089649617671967
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2228628695011139, train_loss: 0.1445893496274948
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22305406630039215, train_loss: 0.13714846968650818
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22362901270389557, train_loss: 0.13397908210754395
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7218255996704102, train_loss: 0.7337445616722107
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3106555938720703, train_loss: 0.21998551487922668
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3062286078929901, train_loss: 0.18634608387947083
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3067725896835327, train_loss: 0.18961718678474426
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30858880281448364, train_loss: 0.17756445705890656
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1138136386871338, train_loss: 1.1753755807876587
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2521779537200928, train_loss: 0.21852414309978485
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21795666217803955, train_loss: 0.14021138846874237
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2193608433008194, train_loss: 0.12724292278289795
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22013497352600098, train_loss: 0.1253911554813385
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5376927256584167, train_loss: 0.6630837917327881
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.091179259121418, train_loss: 0.05711463466286659
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08682532608509064, train_loss: 0.044701773673295975
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08649354428052902, train_loss: 0.04093228280544281
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08626535534858704, train_loss: 0.04048876836895943
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2393680214881897, train_loss: 0.32283687591552734
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06340065598487854, train_loss: 0.047725118696689606
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06193215772509575, train_loss: 0.04068712517619133
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.061731357127428055, train_loss: 0.03944628685712814
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06168564781546593, train_loss: 0.03853387013077736
Trial 7/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 159.55it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 163/2001 [00:01<00:11, 162.15it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 245/2001 [00:01<00:10, 162.80it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 327/2001 [00:02<00:10, 163.05it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 409/2001 [00:02<00:09, 163.22it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 491/2001 [00:03<00:09, 163.34it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 573/2001 [00:03<00:08, 163.32it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 655/2001 [00:04<00:08, 163.26it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 737/2001 [00:04<00:07, 163.34it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 819/2001 [00:05<00:07, 163.39it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 901/2001 [00:05<00:06, 163.32it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 983/2001 [00:06<00:06, 163.36it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1065/2001 [00:06<00:05, 163.43it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1147/2001 [00:07<00:05, 163.42it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1229/2001 [00:07<00:04, 163.46it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1311/2001 [00:08<00:04, 163.51it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1393/2001 [00:08<00:03, 163.43it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1475/2001 [00:09<00:03, 163.50it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1557/2001 [00:09<00:02, 163.53it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1639/2001 [00:10<00:02, 163.52it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1721/2001 [00:10<00:01, 163.52it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1803/2001 [00:11<00:01, 163.53it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1885/2001 [00:11<00:00, 163.55it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1967/2001 [00:12<00:00, 163.57it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.34it/s]
Trial 7: Average Relative Change in Mean Local SHAP Explanations = 1.768620 cosine sim: 0.9706225329433764
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.4936222434043884, train_loss: 0.5168014764785767
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.20984552800655365, train_loss: 0.21210619807243347
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.19837921857833862, train_loss: 0.17730295658111572
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.198173388838768, train_loss: 0.166404128074646
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.19812604784965515, train_loss: 0.1663062572479248
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4385403096675873, train_loss: 0.4595271944999695
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.21026869118213654, train_loss: 0.18389253318309784
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20423880219459534, train_loss: 0.15289521217346191
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20423997938632965, train_loss: 0.14589864015579224
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20459000766277313, train_loss: 0.14224505424499512
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8291861414909363, train_loss: 0.8430749773979187
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2430931180715561, train_loss: 0.23897671699523926
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.21555306017398834, train_loss: 0.1840273141860962
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2135782688856125, train_loss: 0.1652945876121521
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.21369658410549164, train_loss: 0.1617269068956375
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9016876816749573, train_loss: 0.9495874643325806
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2486432045698166, train_loss: 0.18849103152751923
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22522835433483124, train_loss: 0.12106280028820038
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22587652504444122, train_loss: 0.11682944744825363
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2263367474079132, train_loss: 0.11066301167011261
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5572380423545837, train_loss: 0.6907128691673279
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07332876324653625, train_loss: 0.05552646145224571
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.0718417540192604, train_loss: 0.04633067548274994
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07203153520822525, train_loss: 0.04691053554415703
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0720660537481308, train_loss: 0.04597584158182144
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.16929177939891815, train_loss: 0.22257746756076813
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06421013921499252, train_loss: 0.04891157150268555
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06212326139211655, train_loss: 0.037975676357746124
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06218531355261803, train_loss: 0.03652609884738922
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.062197815626859665, train_loss: 0.03526708111166954
Trial 8/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 156.54it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.88it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 162.04it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 325/2001 [00:02<00:10, 162.40it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 407/2001 [00:02<00:09, 162.70it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 489/2001 [00:03<00:09, 162.94it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 571/2001 [00:03<00:08, 162.88it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 653/2001 [00:04<00:08, 163.04it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 735/2001 [00:04<00:07, 163.16it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 817/2001 [00:05<00:07, 163.19it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 899/2001 [00:05<00:06, 163.25it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 981/2001 [00:06<00:06, 163.14it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1063/2001 [00:06<00:05, 163.10it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1145/2001 [00:07<00:05, 163.16it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1227/2001 [00:07<00:04, 163.16it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1309/2001 [00:08<00:04, 163.07it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1391/2001 [00:08<00:03, 163.10it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1473/2001 [00:09<00:03, 163.03it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1555/2001 [00:09<00:02, 162.97it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1637/2001 [00:10<00:02, 162.99it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1719/2001 [00:10<00:01, 163.03it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1801/2001 [00:11<00:01, 163.02it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1883/2001 [00:11<00:00, 163.12it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1965/2001 [00:12<00:00, 163.10it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.87it/s]
Trial 8: Average Relative Change in Mean Local SHAP Explanations = 2.700101 cosine sim: 0.9803914808412822
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.43966808915138245, train_loss: 0.44122815132141113
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.24152973294258118, train_loss: 0.21683770418167114
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23632749915122986, train_loss: 0.18443655967712402
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23677457869052887, train_loss: 0.18100427091121674
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23713165521621704, train_loss: 0.17498129606246948
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6337798833847046, train_loss: 0.6399309039115906
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.24367563426494598, train_loss: 0.2053581178188324
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.23378005623817444, train_loss: 0.16501709818840027
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.23428641259670258, train_loss: 0.1631542444229126
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.23503848910331726, train_loss: 0.15651610493659973
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5784456729888916, train_loss: 0.5980292558670044
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2901111841201782, train_loss: 0.20916226506233215
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.28833532333374023, train_loss: 0.18503430485725403
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2893769443035126, train_loss: 0.18324708938598633
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29077503085136414, train_loss: 0.17852674424648285
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5727705359458923, train_loss: 0.5558357238769531
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.21537408232688904, train_loss: 0.17232759296894073
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20071077346801758, train_loss: 0.12763093411922455
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20104549825191498, train_loss: 0.12123576551675797
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20149846374988556, train_loss: 0.11641812324523926
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.38662463426589966, train_loss: 0.5620567798614502
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08610623329877853, train_loss: 0.05850126966834068
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08308436721563339, train_loss: 0.04638068750500679
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08276194334030151, train_loss: 0.043101243674755096
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08281665295362473, train_loss: 0.0421438030898571
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2537837326526642, train_loss: 0.3752189874649048
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.055406372994184494, train_loss: 0.051761358976364136
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.05474163964390755, train_loss: 0.04195631667971611
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.05493997409939766, train_loss: 0.04118107259273529
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.05511648207902908, train_loss: 0.04047102481126785
Trial 9/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.97it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 160.28it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.70it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 162.29it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 162.63it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 162.82it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 162.92it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 162.88it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 162.94it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 162.97it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 162.82it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 162.84it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 162.93it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 162.92it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 162.97it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 162.87it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 162.84it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 162.92it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 162.98it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 162.95it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 162.94it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 162.99it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 163.01it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 163.05it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.73it/s]
Trial 9: Average Relative Change in Mean Local SHAP Explanations = 1.405989 cosine sim: 0.9804148737170655
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5171260833740234, train_loss: 0.5278111696243286
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.23799504339694977, train_loss: 0.2081151008605957
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.22730694711208344, train_loss: 0.16435618698596954
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.22721272706985474, train_loss: 0.16121137142181396
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.22720208764076233, train_loss: 0.1561869978904724
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5004702210426331, train_loss: 0.5070957541465759
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2224920243024826, train_loss: 0.18073973059654236
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21260160207748413, train_loss: 0.15002793073654175
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2128247171640396, train_loss: 0.1384558081626892
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21298450231552124, train_loss: 0.14110760390758514
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.49141666293144226, train_loss: 0.5019718408584595
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2483961433172226, train_loss: 0.2194627970457077
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.24554161727428436, train_loss: 0.19133667647838593
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24590501189231873, train_loss: 0.19069314002990723
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24618926644325256, train_loss: 0.19397751986980438
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5322975516319275, train_loss: 0.5345560312271118
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.1919092833995819, train_loss: 0.17631256580352783
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.17353098094463348, train_loss: 0.135961651802063
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.173622265458107, train_loss: 0.128738671541214
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.17377446591854095, train_loss: 0.13195979595184326
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3062782287597656, train_loss: 0.3262726664543152
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08599746227264404, train_loss: 0.05349370837211609
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08231864869594574, train_loss: 0.043098047375679016
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08223789930343628, train_loss: 0.04130136966705322
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0821349248290062, train_loss: 0.04088724032044411
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2870592474937439, train_loss: 0.38987308740615845
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06761447340250015, train_loss: 0.047462284564971924
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06658705323934555, train_loss: 0.03806447982788086
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06652040779590607, train_loss: 0.03686296567320824
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06647155433893204, train_loss: 0.03534065559506416
Trial 10/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 156.47it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.70it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 241/2001 [00:01<00:10, 160.56it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 322/2001 [00:02<00:10, 160.96it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 403/2001 [00:02<00:09, 161.11it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 484/2001 [00:03<00:09, 161.29it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 565/2001 [00:03<00:08, 161.32it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 646/2001 [00:04<00:08, 161.40it/s]Shapley Value Sampling attribution:  36%|‚ñà‚ñà‚ñà‚ñã      | 727/2001 [00:04<00:07, 161.34it/s]Shapley Value Sampling attribution:  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2001 [00:05<00:07, 161.42it/s]Shapley Value Sampling attribution:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 889/2001 [00:05<00:06, 161.26it/s]Shapley Value Sampling attribution:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 970/2001 [00:06<00:06, 161.35it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1051/2001 [00:06<00:05, 161.37it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1132/2001 [00:07<00:05, 161.31it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1213/2001 [00:07<00:04, 161.36it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1294/2001 [00:08<00:04, 161.40it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1375/2001 [00:08<00:03, 161.27it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1456/2001 [00:09<00:03, 161.37it/s]Shapley Value Sampling attribution:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1537/2001 [00:09<00:02, 161.40it/s]Shapley Value Sampling attribution:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1618/2001 [00:10<00:02, 161.29it/s]Shapley Value Sampling attribution:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1699/2001 [00:10<00:01, 161.24it/s]Shapley Value Sampling attribution:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1780/2001 [00:11<00:01, 161.34it/s]Shapley Value Sampling attribution:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1861/2001 [00:11<00:00, 161.30it/s]Shapley Value Sampling attribution:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1942/2001 [00:12<00:00, 161.21it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.17it/s]
Trial 10: Average Relative Change in Mean Local SHAP Explanations = 1.190391 cosine sim: 0.9877929721153518
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6780465245246887, train_loss: 0.6881136298179626
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.23821718990802765, train_loss: 0.23457901179790497
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2161921262741089, train_loss: 0.18683694303035736
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.216181218624115, train_loss: 0.17295539379119873
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.21646718680858612, train_loss: 0.167713925242424
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7338623404502869, train_loss: 0.7364513278007507
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2483028918504715, train_loss: 0.18633410334587097
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22728191316127777, train_loss: 0.1313817799091339
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22790652513504028, train_loss: 0.12628957629203796
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22822527587413788, train_loss: 0.11995865404605865
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9008128643035889, train_loss: 0.9161853790283203
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2939763069152832, train_loss: 0.23088087141513824
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2702650725841522, train_loss: 0.1768687665462494
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27003660798072815, train_loss: 0.16675949096679688
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27024737000465393, train_loss: 0.17223143577575684
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9021533727645874, train_loss: 0.9233703017234802
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22510363161563873, train_loss: 0.20546823740005493
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18506118655204773, train_loss: 0.14296650886535645
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.1826174259185791, train_loss: 0.12474477291107178
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18259820342063904, train_loss: 0.11819516122341156
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2589542865753174, train_loss: 0.3046382963657379
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08468693494796753, train_loss: 0.056271713227033615
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08275507390499115, train_loss: 0.04741040989756584
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08275871723890305, train_loss: 0.047129809856414795
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08289960026741028, train_loss: 0.04432607814669609
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3902718126773834, train_loss: 0.49647459387779236
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06958536058664322, train_loss: 0.044473253190517426
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06861276179552078, train_loss: 0.03646263852715492
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06867080926895142, train_loss: 0.03580270707607269
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06881827116012573, train_loss: 0.03519335761666298
Trial 11/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 158.76it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.71it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 162.34it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 162.61it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 162.74it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 162.73it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 162.67it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 162.76it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 162.86it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 162.90it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 162.93it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 162.95it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 162.99it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 162.96it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 162.97it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 162.88it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 162.88it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 162.91it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 162.94it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 162.94it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 162.97it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 162.96it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 162.97it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 162.98it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.80it/s]
Trial 11: Average Relative Change in Mean Local SHAP Explanations = 1.196900 cosine sim: 0.9897715058190832
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7975744009017944, train_loss: 0.839835524559021
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2876967191696167, train_loss: 0.2259364128112793
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2824592888355255, train_loss: 0.1869109869003296
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28366705775260925, train_loss: 0.1841317117214203
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2854151427745819, train_loss: 0.18023042380809784
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8847482204437256, train_loss: 0.9357771873474121
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2527848184108734, train_loss: 0.18907158076763153
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.23077838122844696, train_loss: 0.12195152044296265
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.23187600076198578, train_loss: 0.11395138502120972
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.23301254212856293, train_loss: 0.11379136890172958
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5491836667060852, train_loss: 0.5686897039413452
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2603836953639984, train_loss: 0.20329627394676208
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2579798698425293, train_loss: 0.17541763186454773
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.25850000977516174, train_loss: 0.17168200016021729
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25932663679122925, train_loss: 0.16937661170959473
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9176709651947021, train_loss: 0.9274672269821167
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.25689253211021423, train_loss: 0.2446785718202591
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22535859048366547, train_loss: 0.17581777274608612
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22521072626113892, train_loss: 0.16654902696609497
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22555077075958252, train_loss: 0.16433186829090118
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.308390349149704, train_loss: 0.42081838846206665
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.06914684921503067, train_loss: 0.059833113104104996
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.06854449212551117, train_loss: 0.051570825278759
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.06851240992546082, train_loss: 0.050850916653871536
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.06858746707439423, train_loss: 0.04921402037143707
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.27424320578575134, train_loss: 0.32691749930381775
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07195354998111725, train_loss: 0.05050103738903999
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06795820593833923, train_loss: 0.03721649572253227
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.0678369477391243, train_loss: 0.0343979112803936
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06795152276754379, train_loss: 0.03310006484389305
Trial 12/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 159.43it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 163/2001 [00:01<00:11, 162.27it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 245/2001 [00:01<00:10, 162.78it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 327/2001 [00:02<00:10, 163.05it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 409/2001 [00:02<00:09, 163.18it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 491/2001 [00:03<00:09, 163.25it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 573/2001 [00:03<00:08, 163.30it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 655/2001 [00:04<00:08, 163.33it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 737/2001 [00:04<00:07, 163.38it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 819/2001 [00:05<00:07, 163.29it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 901/2001 [00:05<00:06, 163.31it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 983/2001 [00:06<00:06, 163.33it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1065/2001 [00:06<00:05, 163.35it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1147/2001 [00:07<00:05, 163.34it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1229/2001 [00:07<00:04, 163.35it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1311/2001 [00:08<00:04, 163.38it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1393/2001 [00:08<00:03, 163.38it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1475/2001 [00:09<00:03, 163.38it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1557/2001 [00:09<00:02, 163.40it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1639/2001 [00:10<00:02, 163.32it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1721/2001 [00:10<00:01, 163.28it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1803/2001 [00:11<00:01, 163.32it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1885/2001 [00:11<00:00, 163.35it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1967/2001 [00:12<00:00, 163.20it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.22it/s]
Trial 12: Average Relative Change in Mean Local SHAP Explanations = 1.124633 cosine sim: 0.9924076278754608
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5729354023933411, train_loss: 0.5721704959869385
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.24884440004825592, train_loss: 0.21875697374343872
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23854823410511017, train_loss: 0.17936450242996216
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2385372817516327, train_loss: 0.1800398826599121
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23899021744728088, train_loss: 0.1753430813550949
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7994636297225952, train_loss: 0.8112801313400269
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23977169394493103, train_loss: 0.1988811492919922
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21772877871990204, train_loss: 0.1413651406764984
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21872450411319733, train_loss: 0.13503995537757874
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2193671017885208, train_loss: 0.13298939168453217
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5059167146682739, train_loss: 0.5099978446960449
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27131277322769165, train_loss: 0.19971536099910736
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.27170413732528687, train_loss: 0.18261969089508057
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2725687325000763, train_loss: 0.17832517623901367
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2738620936870575, train_loss: 0.17538192868232727
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7458480596542358, train_loss: 0.7706161737442017
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23655813932418823, train_loss: 0.20277556777000427
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21612490713596344, train_loss: 0.14684145152568817
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21580490469932556, train_loss: 0.1430041790008545
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21573001146316528, train_loss: 0.13949359953403473
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.23305489122867584, train_loss: 0.29470404982566833
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07488787919282913, train_loss: 0.05615712329745293
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07348448783159256, train_loss: 0.045507028698921204
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07353751361370087, train_loss: 0.04509658366441727
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0734938308596611, train_loss: 0.04399717599153519
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.20585688948631287, train_loss: 0.3130744993686676
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06746639311313629, train_loss: 0.048094604164361954
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06454941630363464, train_loss: 0.03896254673600197
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06399421393871307, train_loss: 0.03720128536224365
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06399891525506973, train_loss: 0.036531608551740646
Trial 13/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 154.24it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.40it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 160.85it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.46it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 161.78it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 161.95it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 162.08it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 162.07it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 162.14it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 162.16it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 162.22it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 162.10it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 162.15it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 162.19it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 162.24it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 162.27it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 162.29it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 162.31it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 162.31it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 162.31it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 162.33it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 162.27it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 162.28it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 162.28it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.98it/s]
Trial 13: Average Relative Change in Mean Local SHAP Explanations = 1.039557 cosine sim: 0.9922133856898708
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9974077939987183, train_loss: 1.0247516632080078
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2846497893333435, train_loss: 0.2403911054134369
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2606661915779114, train_loss: 0.18001246452331543
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2606341242790222, train_loss: 0.17582842707633972
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26112180948257446, train_loss: 0.17157594859600067
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8687595129013062, train_loss: 0.9035370945930481
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23822352290153503, train_loss: 0.21444495022296906
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2038898766040802, train_loss: 0.14844951033592224
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20376864075660706, train_loss: 0.13321220874786377
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2039509266614914, train_loss: 0.12581036984920502
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8100239634513855, train_loss: 0.8339328169822693
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.25944197177886963, train_loss: 0.24376356601715088
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2378915399312973, train_loss: 0.19272486865520477
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23813630640506744, train_loss: 0.18373429775238037
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23843510448932648, train_loss: 0.17784713208675385
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6072239875793457, train_loss: 0.6276684999465942
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2261008620262146, train_loss: 0.18248669803142548
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2109484225511551, train_loss: 0.13639093935489655
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21109285950660706, train_loss: 0.1324174404144287
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21137689054012299, train_loss: 0.1298012137413025
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9201564192771912, train_loss: 1.1060616970062256
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07476837188005447, train_loss: 0.05806149169802666
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07358083873987198, train_loss: 0.04700310528278351
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07355771213769913, train_loss: 0.047063007950782776
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07352717965841293, train_loss: 0.0456024631857872
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.24848191440105438, train_loss: 0.2695176303386688
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07017095386981964, train_loss: 0.04469846561551094
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06781473010778427, train_loss: 0.03567252680659294
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06754536181688309, train_loss: 0.036102283746004105
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06748950481414795, train_loss: 0.03428778052330017
Trial 14/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 77/2001 [00:00<00:12, 152.71it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 159/2001 [00:01<00:11, 158.57it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 241/2001 [00:01<00:10, 160.30it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 322/2001 [00:02<00:10, 160.87it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 403/2001 [00:02<00:09, 161.22it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 485/2001 [00:03<00:09, 161.46it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 567/2001 [00:03<00:08, 161.63it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 649/2001 [00:04<00:08, 161.76it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 731/2001 [00:04<00:07, 161.86it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 813/2001 [00:05<00:07, 161.88it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 895/2001 [00:05<00:06, 161.92it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 977/2001 [00:06<00:06, 161.94it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1059/2001 [00:06<00:05, 161.98it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1141/2001 [00:07<00:05, 162.00it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1222/2001 [00:07<00:04, 162.00it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1303/2001 [00:08<00:04, 161.97it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1385/2001 [00:08<00:03, 161.97it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1467/2001 [00:09<00:03, 161.99it/s]Shapley Value Sampling attribution:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1549/2001 [00:09<00:02, 162.00it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1631/2001 [00:10<00:02, 161.99it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1713/2001 [00:10<00:01, 161.99it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1795/2001 [00:11<00:01, 162.00it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1877/2001 [00:11<00:00, 162.00it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1958/2001 [00:12<00:00, 162.00it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.64it/s]
Trial 14: Average Relative Change in Mean Local SHAP Explanations = 1.094547 cosine sim: 0.993508326300185
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6298592686653137, train_loss: 0.644730269908905
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2529303729534149, train_loss: 0.20622649788856506
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2466915249824524, train_loss: 0.17072197794914246
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24733518064022064, train_loss: 0.1668657511472702
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24829058349132538, train_loss: 0.1639878898859024
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7066291570663452, train_loss: 0.7166379690170288
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.225382000207901, train_loss: 0.19154062867164612
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20786821842193604, train_loss: 0.1435883790254593
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20816223323345184, train_loss: 0.13750696182250977
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20853403210639954, train_loss: 0.1328834891319275
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.622545063495636, train_loss: 0.6306420564651489
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.27490803599357605, train_loss: 0.22365576028823853
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2701680660247803, train_loss: 0.19526247680187225
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2707456350326538, train_loss: 0.18933002650737762
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2715331017971039, train_loss: 0.1849742829799652
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4264577031135559, train_loss: 0.4240249991416931
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2137448787689209, train_loss: 0.17263826727867126
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20914700627326965, train_loss: 0.14041012525558472
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20954766869544983, train_loss: 0.1429523080587387
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21005363762378693, train_loss: 0.13480184972286224
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.26533323526382446, train_loss: 0.32348066568374634
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0814274474978447, train_loss: 0.05782965198159218
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07866905629634857, train_loss: 0.04836352542042732
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07834678888320923, train_loss: 0.047022752463817596
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07823086529970169, train_loss: 0.0472991056740284
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.20424850285053253, train_loss: 0.23963434994220734
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06241181120276451, train_loss: 0.04453641176223755
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.061596859246492386, train_loss: 0.03692105412483215
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06164950504899025, train_loss: 0.036506760865449905
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06167411431670189, train_loss: 0.035020723938941956
Trial 15/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 156.94it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.18it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 162.08it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 162.51it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 162.70it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 162.83it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 162.93it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 162.97it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 162.86it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 162.91it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 162.98it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 163.02it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 163.06it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 163.07it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 163.09it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 163.08it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 163.09it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 163.06it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 163.06it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 163.06it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 163.07it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 163.08it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 163.10it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 163.09it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.86it/s]
Trial 15: Average Relative Change in Mean Local SHAP Explanations = 0.944332 cosine sim: 0.9951351018986911
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9068876504898071, train_loss: 0.9430607557296753
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2926657795906067, train_loss: 0.2267896831035614
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2843354344367981, train_loss: 0.17123943567276
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2851998507976532, train_loss: 0.1667087972164154
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28661656379699707, train_loss: 0.16467182338237762
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7116064429283142, train_loss: 0.731727123260498
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2304435670375824, train_loss: 0.21794570982456207
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20356781780719757, train_loss: 0.16929268836975098
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2023078203201294, train_loss: 0.1497473120689392
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20253024995326996, train_loss: 0.14805173873901367
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7682179808616638, train_loss: 0.7868546843528748
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2738873362541199, train_loss: 0.22335951030254364
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2592495083808899, train_loss: 0.17270681262016296
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2596619427204132, train_loss: 0.16795778274536133
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2600591778755188, train_loss: 0.16111692786216736
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6087077856063843, train_loss: 0.6167043447494507
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.20517276227474213, train_loss: 0.17595909535884857
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18095989525318146, train_loss: 0.12037574499845505
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.181009441614151, train_loss: 0.10377387702465057
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18121454119682312, train_loss: 0.10545022040605545
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5000189542770386, train_loss: 0.6657182574272156
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0738605335354805, train_loss: 0.05703117698431015
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07290498912334442, train_loss: 0.045671496540308
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07303956151008606, train_loss: 0.04487952962517738
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.073201023042202, train_loss: 0.04395245388150215
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3234778046607971, train_loss: 0.41124406456947327
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06445182859897614, train_loss: 0.045882146805524826
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.061602454632520676, train_loss: 0.036412328481674194
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06155318766832352, train_loss: 0.03570330888032913
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06146194413304329, train_loss: 0.03520392253994942
Trial 16/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 157.95it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.81it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 161.43it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.63it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 405/2001 [00:02<00:09, 161.69it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 486/2001 [00:03<00:09, 161.78it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 567/2001 [00:03<00:08, 161.79it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 648/2001 [00:04<00:08, 161.67it/s]Shapley Value Sampling attribution:  36%|‚ñà‚ñà‚ñà‚ñã      | 729/2001 [00:04<00:07, 161.71it/s]Shapley Value Sampling attribution:  40%|‚ñà‚ñà‚ñà‚ñà      | 810/2001 [00:05<00:07, 161.78it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 891/2001 [00:05<00:06, 161.77it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 972/2001 [00:06<00:06, 161.70it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1053/2001 [00:06<00:05, 161.73it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1134/2001 [00:07<00:05, 161.79it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1215/2001 [00:07<00:04, 161.78it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1296/2001 [00:08<00:04, 161.79it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1377/2001 [00:08<00:03, 161.68it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1459/2001 [00:09<00:03, 161.76it/s]Shapley Value Sampling attribution:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1540/2001 [00:09<00:02, 161.81it/s]Shapley Value Sampling attribution:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1621/2001 [00:10<00:02, 161.80it/s]Shapley Value Sampling attribution:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1702/2001 [00:10<00:01, 161.82it/s]Shapley Value Sampling attribution:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1783/2001 [00:11<00:01, 161.79it/s]Shapley Value Sampling attribution:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1864/2001 [00:11<00:00, 161.82it/s]Shapley Value Sampling attribution:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1945/2001 [00:12<00:00, 161.79it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.66it/s]
Trial 16: Average Relative Change in Mean Local SHAP Explanations = 0.896812 cosine sim: 0.9942817757432288
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8989276885986328, train_loss: 0.9455467462539673
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3417436480522156, train_loss: 0.23082934319972992
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3323614299297333, train_loss: 0.17730826139450073
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33352339267730713, train_loss: 0.17508022487163544
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33531633019447327, train_loss: 0.16989509761333466
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1239547729492188, train_loss: 1.1709461212158203
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2601713240146637, train_loss: 0.22849473357200623
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20658819377422333, train_loss: 0.14453743398189545
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2033131718635559, train_loss: 0.12806355953216553
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20338907837867737, train_loss: 0.124885194003582
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.4943828284740448, train_loss: 0.5274847745895386
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.23589880764484406, train_loss: 0.21581004559993744
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2290438860654831, train_loss: 0.18074308335781097
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.22936083376407623, train_loss: 0.1740531176328659
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.22975696623325348, train_loss: 0.17580759525299072
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6578971147537231, train_loss: 0.6694467067718506
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.21878163516521454, train_loss: 0.19534987211227417
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.19720828533172607, train_loss: 0.14088663458824158
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.1979384571313858, train_loss: 0.14310947060585022
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.19827139377593994, train_loss: 0.13606669008731842
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.24407516419887543, train_loss: 0.29240551590919495
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07711146771907806, train_loss: 0.05919710919260979
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07604373246431351, train_loss: 0.051109347492456436
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07624920457601547, train_loss: 0.04996199160814285
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0763775184750557, train_loss: 0.04917381331324577
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6563123464584351, train_loss: 0.7667732238769531
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06798690557479858, train_loss: 0.04426039382815361
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06680680066347122, train_loss: 0.03637468069791794
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06678944826126099, train_loss: 0.03491602838039398
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.066813625395298, train_loss: 0.03439604118466377
Trial 17/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 154.69it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.61it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 160.95it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 323/2001 [00:02<00:10, 161.36it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 405/2001 [00:02<00:09, 161.65it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 487/2001 [00:03<00:09, 161.84it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 569/2001 [00:03<00:08, 161.95it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 651/2001 [00:04<00:08, 162.01it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 733/2001 [00:04<00:07, 162.07it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 815/2001 [00:05<00:07, 162.08it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 897/2001 [00:05<00:06, 162.11it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 979/2001 [00:06<00:06, 162.14it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1061/2001 [00:06<00:05, 162.07it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1143/2001 [00:07<00:05, 162.02it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1225/2001 [00:07<00:04, 162.03it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1307/2001 [00:08<00:04, 162.04it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1389/2001 [00:08<00:03, 162.08it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1471/2001 [00:09<00:03, 162.10it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1553/2001 [00:09<00:02, 162.11it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1635/2001 [00:10<00:02, 162.12it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1717/2001 [00:10<00:01, 162.12it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1799/2001 [00:11<00:01, 162.04it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1881/2001 [00:11<00:00, 162.06it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1963/2001 [00:12<00:00, 162.05it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.85it/s]
Trial 17: Average Relative Change in Mean Local SHAP Explanations = 12.902568 cosine sim: 0.9959551510307242
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7066724896430969, train_loss: 0.7037334442138672
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.28390657901763916, train_loss: 0.2245699018239975
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2791372537612915, train_loss: 0.18750762939453125
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2803006172180176, train_loss: 0.18411573767662048
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28174832463264465, train_loss: 0.18229100108146667
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7018505930900574, train_loss: 0.7368718981742859
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.24656899273395538, train_loss: 0.1864098757505417
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2350727617740631, train_loss: 0.13961459696292877
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.23548296093940735, train_loss: 0.1373220682144165
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.23631814122200012, train_loss: 0.13340066373348236
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0064811706542969, train_loss: 1.0254220962524414
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2654028832912445, train_loss: 0.23153352737426758
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23079527914524078, train_loss: 0.16548305749893188
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23034299910068512, train_loss: 0.1539394110441208
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23060745000839233, train_loss: 0.15322434902191162
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.638091504573822, train_loss: 0.6515136361122131
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22346250712871552, train_loss: 0.18869934976100922
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20894038677215576, train_loss: 0.1426854133605957
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20897366106510162, train_loss: 0.13485124707221985
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20944243669509888, train_loss: 0.1329941600561142
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2800310552120209, train_loss: 0.3831634521484375
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07265705615282059, train_loss: 0.05841738358139992
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.0703776553273201, train_loss: 0.05022410303354263
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07013138383626938, train_loss: 0.04919857531785965
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0701063871383667, train_loss: 0.047165367752313614
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.27970364689826965, train_loss: 0.37196072936058044
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.0779593288898468, train_loss: 0.048437830060720444
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.07394729554653168, train_loss: 0.037537992000579834
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.07407121360301971, train_loss: 0.03605471923947334
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07400994747877121, train_loss: 0.03494744375348091
Trial 18/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 158.80it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.38it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 161.96it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 162.04it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 162.08it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 162.12it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 162.12it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 162.14it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 162.15it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 162.17it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 162.17it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 162.17it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 162.16it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 162.17it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 162.16it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 162.17it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 162.17it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 162.17it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 162.17it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 162.19it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 162.19it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 162.21it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 162.20it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 162.19it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.09it/s]
Trial 18: Average Relative Change in Mean Local SHAP Explanations = 0.827033 cosine sim: 0.9961032561657683
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5389367938041687, train_loss: 0.5432009696960449
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2996954023838043, train_loss: 0.1943248063325882
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3028721213340759, train_loss: 0.17103546857833862
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3051355183124542, train_loss: 0.1673191636800766
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.308133602142334, train_loss: 0.16314701735973358
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.2872017621994019, train_loss: 1.28883957862854
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.26287248730659485, train_loss: 0.23820841312408447
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20377515256404877, train_loss: 0.15947648882865906
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2018856406211853, train_loss: 0.14074769616127014
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2022736668586731, train_loss: 0.13403567671775818
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9390394687652588, train_loss: 0.9807884097099304
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2739078104496002, train_loss: 0.2595159411430359
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23390398919582367, train_loss: 0.19173167645931244
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23324711620807648, train_loss: 0.17565059661865234
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23330220580101013, train_loss: 0.17147508263587952
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1004189252853394, train_loss: 1.1165201663970947
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2555641531944275, train_loss: 0.21642127633094788
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20685121417045593, train_loss: 0.15401509404182434
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20212309062480927, train_loss: 0.12285292148590088
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20215561985969543, train_loss: 0.12393645942211151
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3645889461040497, train_loss: 0.39068329334259033
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08386795222759247, train_loss: 0.05961426720023155
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08040410280227661, train_loss: 0.045171864330768585
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08035015314817429, train_loss: 0.0423562191426754
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08052583783864975, train_loss: 0.04149815812706947
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4960814118385315, train_loss: 0.6241418123245239
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07581886649131775, train_loss: 0.05020758882164955
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.07065501809120178, train_loss: 0.038099464029073715
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06963115930557251, train_loss: 0.03554505854845047
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06960049271583557, train_loss: 0.034751422703266144
Trial 19/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 158.96it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.90it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 162.58it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 162.71it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 162.78it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 162.82it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 162.86it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 162.88it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 162.87it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 162.84it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 162.86it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 162.87it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 162.87it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 162.85it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 162.86it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 162.85it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 162.85it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 162.85it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 162.85it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 162.86it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 162.85it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 162.85it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 162.85it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 162.83it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.76it/s]
Trial 19: Average Relative Change in Mean Local SHAP Explanations = 1.047635 cosine sim: 0.9959669732090968
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5747668147087097, train_loss: 0.5764959454536438
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2937444746494293, train_loss: 0.19441775977611542
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29394567012786865, train_loss: 0.16599200665950775
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29509055614471436, train_loss: 0.16064482927322388
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2967977821826935, train_loss: 0.16441789269447327
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7255014181137085, train_loss: 0.7411526441574097
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2099178284406662, train_loss: 0.1997372806072235
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.19101835787296295, train_loss: 0.14378172159194946
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.191470667719841, train_loss: 0.1374305933713913
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.19188864529132843, train_loss: 0.135313019156456
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8340290188789368, train_loss: 0.8718506693840027
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2571578621864319, train_loss: 0.24213707447052002
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23460687696933746, train_loss: 0.19162867963314056
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23554998636245728, train_loss: 0.17564211785793304
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23578152060508728, train_loss: 0.17314878106117249
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4858236312866211, train_loss: 0.5079607963562012
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.1834336817264557, train_loss: 0.17862412333488464
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.1713450700044632, train_loss: 0.14360979199409485
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.17177265882492065, train_loss: 0.13875310122966766
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.17187613248825073, train_loss: 0.13968437910079956
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.23129193484783173, train_loss: 0.250529021024704
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08827201277017593, train_loss: 0.056012630462646484
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08536819368600845, train_loss: 0.04584701731801033
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.0853743776679039, train_loss: 0.04286383464932442
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08545960485935211, train_loss: 0.041321028023958206
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2673739790916443, train_loss: 0.36770787835121155
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07508233189582825, train_loss: 0.04194506257772446
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.07308781147003174, train_loss: 0.03571480140089989
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.0728091150522232, train_loss: 0.03500407189130783
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07273751497268677, train_loss: 0.033708930015563965
Trial 20/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 157.80it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.81it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 161.77it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 325/2001 [00:02<00:10, 161.97it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 161.96it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 487/2001 [00:03<00:09, 161.89it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 568/2001 [00:03<00:08, 161.90it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 649/2001 [00:04<00:08, 161.84it/s]Shapley Value Sampling attribution:  36%|‚ñà‚ñà‚ñà‚ñã      | 730/2001 [00:04<00:07, 161.86it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 811/2001 [00:05<00:07, 161.81it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 892/2001 [00:05<00:06, 161.85it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 973/2001 [00:06<00:06, 161.80it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1054/2001 [00:06<00:05, 161.83it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1135/2001 [00:07<00:05, 161.78it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1216/2001 [00:07<00:04, 161.82it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1297/2001 [00:08<00:04, 161.79it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1378/2001 [00:08<00:03, 161.83it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1459/2001 [00:09<00:03, 161.81it/s]Shapley Value Sampling attribution:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1540/2001 [00:09<00:02, 161.84it/s]Shapley Value Sampling attribution:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1621/2001 [00:10<00:02, 161.80it/s]Shapley Value Sampling attribution:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1702/2001 [00:10<00:01, 161.83it/s]Shapley Value Sampling attribution:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1783/2001 [00:11<00:01, 161.65it/s]Shapley Value Sampling attribution:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1864/2001 [00:11<00:00, 161.71it/s]Shapley Value Sampling attribution:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1945/2001 [00:12<00:00, 161.70it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.73it/s]
Trial 20: Average Relative Change in Mean Local SHAP Explanations = 0.697028 cosine sim: 0.9965716522810495
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6874852180480957, train_loss: 0.7011322975158691
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2534658908843994, train_loss: 0.2358822524547577
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23579348623752594, train_loss: 0.18953797221183777
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23603172600269318, train_loss: 0.18384632468223572
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23627202212810516, train_loss: 0.17771205306053162
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9430427551269531, train_loss: 0.9717839360237122
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23227472603321075, train_loss: 0.21318167448043823
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.19066601991653442, train_loss: 0.14068603515625
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.18921001255512238, train_loss: 0.13487903773784637
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18914759159088135, train_loss: 0.12563523650169373
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8040918707847595, train_loss: 0.8407403826713562
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2994465231895447, train_loss: 0.21094577014446259
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2952300012111664, train_loss: 0.1685752123594284
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.296633243560791, train_loss: 0.16841070353984833
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29851803183555603, train_loss: 0.16029423475265503
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9466717839241028, train_loss: 0.9859591722488403
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.27856552600860596, train_loss: 0.22953476011753082
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.24817903339862823, train_loss: 0.1522330641746521
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.24883320927619934, train_loss: 0.14687369763851166
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.24947038292884827, train_loss: 0.1404554843902588
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.47321850061416626, train_loss: 0.6081108450889587
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07416578382253647, train_loss: 0.06141166761517525
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07161819189786911, train_loss: 0.05134694650769234
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.0715881809592247, train_loss: 0.049852531403303146
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07144330441951752, train_loss: 0.04924561083316803
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2457389533519745, train_loss: 0.29250243306159973
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07428783923387527, train_loss: 0.04812037944793701
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.0715358778834343, train_loss: 0.03711232915520668
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.07111801952123642, train_loss: 0.03577274829149246
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07093416154384613, train_loss: 0.035541582852602005
Trial 21/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 156.04it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.42it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 161.61it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 325/2001 [00:02<00:10, 162.34it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 407/2001 [00:02<00:09, 162.73it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 489/2001 [00:03<00:09, 162.63it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 571/2001 [00:03<00:08, 162.53it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 653/2001 [00:04<00:08, 162.47it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 735/2001 [00:04<00:07, 162.44it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 817/2001 [00:05<00:07, 162.41it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 899/2001 [00:05<00:06, 162.39it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 981/2001 [00:06<00:06, 162.35it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1063/2001 [00:06<00:05, 162.35it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1145/2001 [00:07<00:05, 162.35it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1227/2001 [00:07<00:04, 162.36it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1309/2001 [00:08<00:04, 162.36it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1391/2001 [00:08<00:03, 162.35it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1473/2001 [00:09<00:03, 162.33it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1555/2001 [00:09<00:02, 162.34it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1637/2001 [00:10<00:02, 162.34it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1719/2001 [00:10<00:01, 162.32it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1801/2001 [00:11<00:01, 162.31it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1883/2001 [00:11<00:00, 162.32it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1965/2001 [00:12<00:00, 162.34it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.24it/s]
Trial 21: Average Relative Change in Mean Local SHAP Explanations = 0.691416 cosine sim: 0.995625802723227
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5867081880569458, train_loss: 0.5765856504440308
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.28118896484375, train_loss: 0.21449381113052368
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2785797119140625, train_loss: 0.18026837706565857
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2790473401546478, train_loss: 0.1828625649213791
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2800091505050659, train_loss: 0.1745537519454956
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7118305563926697, train_loss: 0.7235092520713806
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22524377703666687, train_loss: 0.19813847541809082
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2013891041278839, train_loss: 0.14784082770347595
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.2016368955373764, train_loss: 0.13623222708702087
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2021089494228363, train_loss: 0.13389161229133606
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7843344211578369, train_loss: 0.7923464179039001
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2797994911670685, train_loss: 0.22396761178970337
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.25937530398368835, train_loss: 0.17131608724594116
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2596733570098877, train_loss: 0.15377873182296753
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2599538564682007, train_loss: 0.15037451684474945
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8901189565658569, train_loss: 0.9150140285491943
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2338138371706009, train_loss: 0.21901464462280273
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.1947353333234787, train_loss: 0.15754136443138123
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.19309817254543304, train_loss: 0.13638126850128174
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.193401500582695, train_loss: 0.1298588514328003
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.1720447838306427, train_loss: 0.22542418539524078
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07605551183223724, train_loss: 0.05662165582180023
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07560637593269348, train_loss: 0.04952753707766533
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.0756300836801529, train_loss: 0.04903502017259598
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07574781030416489, train_loss: 0.047929439693689346
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6857410073280334, train_loss: 0.7856078743934631
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07378548383712769, train_loss: 0.047405678778886795
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.0704391822218895, train_loss: 0.03688725829124451
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.07007566094398499, train_loss: 0.03492136672139168
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.0700225979089737, train_loss: 0.03385337069630623
Trial 22/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 155.49it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.87it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.19it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.79it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 162.11it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 162.31it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 162.43it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 162.44it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 162.53it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 162.60it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 162.63it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 162.66it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 162.69it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 162.71it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 162.72it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 162.71it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 162.68it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 162.67it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 162.67it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 162.65it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 162.54it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 162.46it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 162.35it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 162.33it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.31it/s]
Trial 22: Average Relative Change in Mean Local SHAP Explanations = 0.871437 cosine sim: 0.9976202469516819
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9941624999046326, train_loss: 0.9892980456352234
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26807498931884766, train_loss: 0.24903422594070435
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23368778824806213, train_loss: 0.1853238046169281
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23348833620548248, train_loss: 0.17021679878234863
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23376484215259552, train_loss: 0.17225518822669983
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6861954927444458, train_loss: 0.6940772533416748
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.21631436049938202, train_loss: 0.19176435470581055
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18930181860923767, train_loss: 0.14153341948986053
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.18858398497104645, train_loss: 0.12095382064580917
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18877966701984406, train_loss: 0.12389535456895828
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8105365037918091, train_loss: 0.8117555379867554
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26702097058296204, train_loss: 0.23878733813762665
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2479555904865265, train_loss: 0.193862646818161
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24807383120059967, train_loss: 0.1904011368751526
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2483048290014267, train_loss: 0.18911950290203094
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7660250067710876, train_loss: 0.7822346687316895
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.24137476086616516, train_loss: 0.20374484360218048
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2178838551044464, train_loss: 0.15504369139671326
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21834969520568848, train_loss: 0.1494336575269699
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21851739287376404, train_loss: 0.14591431617736816
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7567501664161682, train_loss: 0.8771939873695374
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.08256670832633972, train_loss: 0.05848916247487068
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08025266975164413, train_loss: 0.04572073742747307
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08048497885465622, train_loss: 0.04338088631629944
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08055728673934937, train_loss: 0.042991816997528076
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2248300462961197, train_loss: 0.3207162320613861
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06322523206472397, train_loss: 0.04895438998937607
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06101786345243454, train_loss: 0.039239995181560516
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.060920704156160355, train_loss: 0.03812842443585396
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06098092347383499, train_loss: 0.037648532539606094
Trial 23/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 158.88it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 162/2001 [00:01<00:11, 161.39it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 244/2001 [00:01<00:10, 162.06it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 326/2001 [00:02<00:10, 162.40it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 408/2001 [00:02<00:09, 162.59it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 490/2001 [00:03<00:09, 162.69it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 572/2001 [00:03<00:08, 162.77it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 654/2001 [00:04<00:08, 162.82it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 736/2001 [00:04<00:07, 162.85it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 818/2001 [00:05<00:07, 162.86it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 900/2001 [00:05<00:06, 162.87it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 982/2001 [00:06<00:06, 162.87it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1064/2001 [00:06<00:05, 162.87it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1146/2001 [00:07<00:05, 162.88it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1228/2001 [00:07<00:04, 162.91it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1310/2001 [00:08<00:04, 162.90it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1392/2001 [00:08<00:03, 162.90it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1474/2001 [00:09<00:03, 162.90it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1556/2001 [00:09<00:02, 162.91it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1638/2001 [00:10<00:02, 162.90it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1720/2001 [00:10<00:01, 162.89it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1802/2001 [00:11<00:01, 162.89it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1884/2001 [00:11<00:00, 162.87it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1966/2001 [00:12<00:00, 162.86it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.73it/s]
Trial 23: Average Relative Change in Mean Local SHAP Explanations = 1.175717 cosine sim: 0.9971209824032821
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7032391428947449, train_loss: 0.7271057963371277
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26626139879226685, train_loss: 0.22927038371562958
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2546364963054657, train_loss: 0.19057732820510864
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.25504404306411743, train_loss: 0.18740420043468475
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25553202629089355, train_loss: 0.18417565524578094
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.720872163772583, train_loss: 0.7367450594902039
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.24170057475566864, train_loss: 0.1897926926612854
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22374358773231506, train_loss: 0.14190396666526794
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22464096546173096, train_loss: 0.1282748281955719
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.225570946931839, train_loss: 0.13276511430740356
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5509321093559265, train_loss: 0.5702964663505554
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.21582621335983276, train_loss: 0.23675571382045746
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.1955975443124771, train_loss: 0.19614975154399872
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.1947447657585144, train_loss: 0.18379122018814087
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.19456540048122406, train_loss: 0.17787516117095947
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8186661005020142, train_loss: 0.8311602473258972
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2385661005973816, train_loss: 0.1940733641386032
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.21505001187324524, train_loss: 0.13392922282218933
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21495592594146729, train_loss: 0.1258256435394287
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21539773046970367, train_loss: 0.12884986400604248
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2737089693546295, train_loss: 0.3230510950088501
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.09196075052022934, train_loss: 0.058448709547519684
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08903121948242188, train_loss: 0.04679826647043228
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.0888923704624176, train_loss: 0.04501991719007492
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.08886463195085526, train_loss: 0.043089594691991806
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.40795376896858215, train_loss: 0.5044803023338318
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06747022271156311, train_loss: 0.04414457827806473
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06530062109231949, train_loss: 0.03442922979593277
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06524132937192917, train_loss: 0.031141318380832672
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06537549942731857, train_loss: 0.030748678371310234
Trial 24/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 79/2001 [00:00<00:12, 157.28it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 161/2001 [00:01<00:11, 160.93it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 243/2001 [00:01<00:10, 161.86it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 325/2001 [00:02<00:10, 162.29it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 407/2001 [00:02<00:09, 162.53it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 489/2001 [00:03<00:09, 162.66it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 571/2001 [00:03<00:08, 162.75it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 653/2001 [00:04<00:08, 162.81it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 735/2001 [00:04<00:07, 162.84it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 817/2001 [00:05<00:07, 162.84it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 899/2001 [00:05<00:06, 162.86it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 981/2001 [00:06<00:06, 162.88it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1063/2001 [00:06<00:05, 162.88it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1145/2001 [00:07<00:05, 162.89it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1227/2001 [00:07<00:04, 162.89it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1309/2001 [00:08<00:04, 162.91it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1391/2001 [00:08<00:03, 162.92it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1473/2001 [00:09<00:03, 162.93it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1555/2001 [00:09<00:02, 162.94it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1637/2001 [00:10<00:02, 162.93it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1719/2001 [00:10<00:01, 162.93it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1801/2001 [00:11<00:01, 162.93it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1883/2001 [00:11<00:00, 162.92it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1965/2001 [00:12<00:00, 162.90it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.71it/s]
Trial 24: Average Relative Change in Mean Local SHAP Explanations = 0.716669 cosine sim: 0.9971004071687399
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6291350722312927, train_loss: 0.6555919647216797
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2881024479866028, train_loss: 0.2174016535282135
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.28691110014915466, train_loss: 0.19253359735012054
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28807875514030457, train_loss: 0.18513576686382294
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28923478722572327, train_loss: 0.18021100759506226
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7913393378257751, train_loss: 0.8196207284927368
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2249995470046997, train_loss: 0.20688912272453308
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.1957695633172989, train_loss: 0.1569330394268036
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.19422370195388794, train_loss: 0.14247481524944305
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.19420979917049408, train_loss: 0.1393279731273651
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7692160606384277, train_loss: 0.7711421847343445
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2606409192085266, train_loss: 0.22482830286026
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23938190937042236, train_loss: 0.17934273183345795
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23897486925125122, train_loss: 0.16794118285179138
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23908232152462006, train_loss: 0.1655092090368271
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5502223372459412, train_loss: 0.5586286783218384
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23253221809864044, train_loss: 0.1617201417684555
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2258874475955963, train_loss: 0.12670603394508362
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22632268071174622, train_loss: 0.12572303414344788
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22698627412319183, train_loss: 0.12267502397298813
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2017025351524353, train_loss: 0.2575593888759613
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07494950294494629, train_loss: 0.05976913496851921
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07436319440603256, train_loss: 0.04939451068639755
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07437383383512497, train_loss: 0.04821803420782089
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07448505610227585, train_loss: 0.04694002866744995
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2440749704837799, train_loss: 0.2868260145187378
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07159507274627686, train_loss: 0.046633362770080566
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06753901392221451, train_loss: 0.03512708470225334
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06712614744901657, train_loss: 0.03435475379228592
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06704393029212952, train_loss: 0.033410485833883286
Trial 25/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 158.79it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 163/2001 [00:01<00:11, 162.48it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 246/2001 [00:01<00:10, 163.39it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 329/2001 [00:02<00:10, 163.76it/s]Shapley Value Sampling attribution:  21%|‚ñà‚ñà        | 412/2001 [00:02<00:09, 164.01it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 495/2001 [00:03<00:09, 164.10it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñâ       | 578/2001 [00:03<00:08, 164.20it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 661/2001 [00:04<00:08, 164.21it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 744/2001 [00:04<00:07, 164.29it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 827/2001 [00:05<00:07, 164.27it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 910/2001 [00:05<00:06, 164.33it/s]Shapley Value Sampling attribution:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 993/2001 [00:06<00:06, 164.30it/s]Shapley Value Sampling attribution:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1076/2001 [00:06<00:05, 164.35it/s]Shapley Value Sampling attribution:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1159/2001 [00:07<00:05, 164.33it/s]Shapley Value Sampling attribution:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1242/2001 [00:07<00:04, 164.37it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1325/2001 [00:08<00:04, 164.33it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1408/2001 [00:08<00:03, 164.37it/s]Shapley Value Sampling attribution:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1491/2001 [00:09<00:03, 164.31it/s]Shapley Value Sampling attribution:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1574/2001 [00:09<00:02, 164.34it/s]Shapley Value Sampling attribution:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1657/2001 [00:10<00:02, 164.30it/s]Shapley Value Sampling attribution:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1740/2001 [00:10<00:01, 164.34it/s]Shapley Value Sampling attribution:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1823/2001 [00:11<00:01, 164.30it/s]Shapley Value Sampling attribution:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1906/2001 [00:11<00:00, 164.32it/s]Shapley Value Sampling attribution:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1989/2001 [00:12<00:00, 164.29it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 164.14it/s]
Trial 25: Average Relative Change in Mean Local SHAP Explanations = 0.769428 cosine sim: 0.9971412596854468
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6264709830284119, train_loss: 0.6371890306472778
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.24587643146514893, train_loss: 0.23152971267700195
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.21620658040046692, train_loss: 0.18604445457458496
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.21468625962734222, train_loss: 0.16752901673316956
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.21481524407863617, train_loss: 0.16333319246768951
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7480231523513794, train_loss: 0.7778255939483643
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2305268496274948, train_loss: 0.1968294382095337
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.20430965721607208, train_loss: 0.151772141456604
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20323485136032104, train_loss: 0.1379489004611969
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.20334117114543915, train_loss: 0.13424932956695557
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6682235598564148, train_loss: 0.7018234133720398
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.261871874332428, train_loss: 0.24082277715206146
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.24697408080101013, train_loss: 0.19316725432872772
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24725371599197388, train_loss: 0.18916182219982147
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2477332502603531, train_loss: 0.1773301213979721
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6268221735954285, train_loss: 0.6450013518333435
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.21327993273735046, train_loss: 0.1891518235206604
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.1923017054796219, train_loss: 0.14391043782234192
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.1923171877861023, train_loss: 0.13056153059005737
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.19249063730239868, train_loss: 0.1272941678762436
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.29314419627189636, train_loss: 0.39778634905815125
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.09371773898601532, train_loss: 0.05680955946445465
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.09046067297458649, train_loss: 0.048260170966386795
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.09056388586759567, train_loss: 0.04758860915899277
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.09031321108341217, train_loss: 0.04600376635789871
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.30337029695510864, train_loss: 0.41537103056907654
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.08171685039997101, train_loss: 0.044593293219804764
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.08025297522544861, train_loss: 0.03909001871943474
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.08021051436662674, train_loss: 0.03827696293592453
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07999487966299057, train_loss: 0.03630271553993225
Trial 26/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 159.86it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 163/2001 [00:01<00:11, 162.26it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 245/2001 [00:01<00:10, 162.79it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 327/2001 [00:02<00:10, 162.97it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 409/2001 [00:02<00:09, 163.06it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 491/2001 [00:03<00:09, 163.11it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñä       | 573/2001 [00:03<00:08, 163.14it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 655/2001 [00:04<00:08, 163.16it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 737/2001 [00:04<00:07, 163.16it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 819/2001 [00:05<00:07, 163.19it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 901/2001 [00:05<00:06, 163.18it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 983/2001 [00:06<00:06, 163.19it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1065/2001 [00:06<00:05, 163.21it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1147/2001 [00:07<00:05, 163.19it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1229/2001 [00:07<00:04, 163.18it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1311/2001 [00:08<00:04, 163.18it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1393/2001 [00:08<00:03, 163.18it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1475/2001 [00:09<00:03, 163.18it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1557/2001 [00:09<00:02, 163.17it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1639/2001 [00:10<00:02, 163.17it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1721/2001 [00:10<00:01, 163.16it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1803/2001 [00:11<00:01, 163.17it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1885/2001 [00:11<00:00, 162.99it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1967/2001 [00:12<00:00, 163.03it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.06it/s]
Trial 26: Average Relative Change in Mean Local SHAP Explanations = 0.721006 cosine sim: 0.9975548311820833
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8259092569351196, train_loss: 0.8486682176589966
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2627638578414917, train_loss: 0.25825947523117065
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.23620405793190002, train_loss: 0.21198809146881104
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23633475601673126, train_loss: 0.19451797008514404
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2364342361688614, train_loss: 0.197183296084404
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8205388784408569, train_loss: 0.8569507002830505
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2499433308839798, train_loss: 0.2278500199317932
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.22528314590454102, train_loss: 0.16844940185546875
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.22654229402542114, train_loss: 0.15233305096626282
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.22716359794139862, train_loss: 0.14776748418807983
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.82752525806427, train_loss: 0.8496065139770508
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26009508967399597, train_loss: 0.23100340366363525
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2364007830619812, train_loss: 0.17435643076896667
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2361748367547989, train_loss: 0.16725561022758484
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.23644180595874786, train_loss: 0.15898551046848297
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5971587896347046, train_loss: 0.6134653687477112
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.20215454697608948, train_loss: 0.17878559231758118
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18125556409358978, train_loss: 0.13060453534126282
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.17965123057365417, train_loss: 0.11723141372203827
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.1798158586025238, train_loss: 0.11037689447402954
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.18601520359516144, train_loss: 0.2567722201347351
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07267451286315918, train_loss: 0.059327319264411926
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.0716056078672409, train_loss: 0.0494014173746109
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07168927043676376, train_loss: 0.048461418598890305
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07183423638343811, train_loss: 0.04681019112467766
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4360456168651581, train_loss: 0.5600787401199341
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.07607849687337875, train_loss: 0.0477147251367569
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.07343431562185287, train_loss: 0.03684748336672783
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.07302624732255936, train_loss: 0.035601597279310226
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.07300055772066116, train_loss: 0.03555293753743172
Trial 27/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 154.98it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 159.89it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.37it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 161.93it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 162.23it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 162.41it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 162.56it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 162.62it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 162.67it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 162.71it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 162.72it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 162.74it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 162.74it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 162.73it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 162.74it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 162.76it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 162.75it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 162.75it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 162.74it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 162.74it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 162.74it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 162.75it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 162.74it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 162.74it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 162.47it/s]
Trial 27: Average Relative Change in Mean Local SHAP Explanations = 0.652675 cosine sim: 0.9974322024342627
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6605286002159119, train_loss: 0.6918854713439941
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.30325523018836975, train_loss: 0.21794316172599792
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3016524016857147, train_loss: 0.18259209394454956
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3029554784297943, train_loss: 0.18121661245822906
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3048785328865051, train_loss: 0.17017459869384766
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6072577238082886, train_loss: 0.6295042634010315
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.2113284170627594, train_loss: 0.1954653263092041
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.19750337302684784, train_loss: 0.15045584738254547
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.19770078361034393, train_loss: 0.15163926780223846
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.1979159414768219, train_loss: 0.14594511687755585
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6379255652427673, train_loss: 0.6580605506896973
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.25838181376457214, train_loss: 0.23633281886577606
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.24628233909606934, train_loss: 0.19390486180782318
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.24655285477638245, train_loss: 0.19371061027050018
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24691864848136902, train_loss: 0.1892521232366562
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6978818774223328, train_loss: 0.709298849105835
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.22187842428684235, train_loss: 0.1957288682460785
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2020150125026703, train_loss: 0.1412752866744995
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.20244549214839935, train_loss: 0.13439993560314178
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2029504030942917, train_loss: 0.13088953495025635
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7242527008056641, train_loss: 0.9107648134231567
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0793074518442154, train_loss: 0.05896568298339844
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07713726907968521, train_loss: 0.049754898995161057
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07698950916528702, train_loss: 0.046926312148571014
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07694979012012482, train_loss: 0.046211015433073044
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2709465026855469, train_loss: 0.37814679741859436
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06457958370447159, train_loss: 0.04860467463731766
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06334401667118073, train_loss: 0.040749747306108475
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.0633871853351593, train_loss: 0.04007437452673912
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.06348028033971786, train_loss: 0.03861194849014282
Trial 28/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 80/2001 [00:00<00:12, 159.40it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 163/2001 [00:01<00:11, 162.46it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 246/2001 [00:01<00:10, 163.40it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñã        | 329/2001 [00:02<00:10, 163.63it/s]Shapley Value Sampling attribution:  21%|‚ñà‚ñà        | 412/2001 [00:02<00:09, 163.82it/s]Shapley Value Sampling attribution:  25%|‚ñà‚ñà‚ñç       | 495/2001 [00:03<00:09, 163.88it/s]Shapley Value Sampling attribution:  29%|‚ñà‚ñà‚ñâ       | 577/2001 [00:03<00:08, 163.92it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 660/2001 [00:04<00:08, 163.99it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 743/2001 [00:04<00:07, 163.98it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 826/2001 [00:05<00:07, 164.02it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 909/2001 [00:05<00:06, 163.98it/s]Shapley Value Sampling attribution:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 992/2001 [00:06<00:06, 164.02it/s]Shapley Value Sampling attribution:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1075/2001 [00:06<00:05, 163.99it/s]Shapley Value Sampling attribution:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1157/2001 [00:07<00:05, 163.85it/s]Shapley Value Sampling attribution:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1239/2001 [00:07<00:04, 163.90it/s]Shapley Value Sampling attribution:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1321/2001 [00:08<00:04, 163.91it/s]Shapley Value Sampling attribution:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1404/2001 [00:08<00:03, 163.98it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1487/2001 [00:09<00:03, 163.97it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1570/2001 [00:09<00:02, 164.01it/s]Shapley Value Sampling attribution:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1653/2001 [00:10<00:02, 163.99it/s]Shapley Value Sampling attribution:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1735/2001 [00:10<00:01, 163.98it/s]Shapley Value Sampling attribution:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1818/2001 [00:11<00:01, 164.03it/s]Shapley Value Sampling attribution:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1901/2001 [00:11<00:00, 163.99it/s]Shapley Value Sampling attribution:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1983/2001 [00:12<00:00, 163.99it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.85it/s]
Trial 28: Average Relative Change in Mean Local SHAP Explanations = 0.655876 cosine sim: 0.9982462720112447
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8766449093818665, train_loss: 0.874868631362915
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.2828895151615143, train_loss: 0.24754935503005981
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2612350583076477, train_loss: 0.19042032957077026
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26221445202827454, train_loss: 0.18567588925361633
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26295220851898193, train_loss: 0.18179422616958618
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7304533123970032, train_loss: 0.7405678629875183
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.25453874468803406, train_loss: 0.20947358012199402
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.23572641611099243, train_loss: 0.1618639975786209
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.23577357828617096, train_loss: 0.15892167389392853
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2360748052597046, train_loss: 0.15452350676059723
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.49547022581100464, train_loss: 0.49493199586868286
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.26378217339515686, train_loss: 0.19913026690483093
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2611353099346161, train_loss: 0.17544691264629364
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26158878207206726, train_loss: 0.17262625694274902
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2623984217643738, train_loss: 0.16992352902889252
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6295955777168274, train_loss: 0.641782283782959
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.20905587077140808, train_loss: 0.1923852413892746
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18413598835468292, train_loss: 0.14115212857723236
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.18384142220020294, train_loss: 0.1205158680677414
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.18365952372550964, train_loss: 0.11948180198669434
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2502489984035492, train_loss: 0.33295738697052
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.0849105715751648, train_loss: 0.05831088870763779
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.08297371119260788, train_loss: 0.04633992165327072
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.08267858624458313, train_loss: 0.04416400566697121
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.0827537402510643, train_loss: 0.04287860170006752
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2200249582529068, train_loss: 0.29066765308380127
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.06970760971307755, train_loss: 0.047817666083574295
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06709051132202148, train_loss: 0.03820245712995529
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.067085862159729, train_loss: 0.037069257348775864
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.0669577568769455, train_loss: 0.035859595984220505
Trial 29/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 154.27it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 158.96it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 241/2001 [00:01<00:10, 160.32it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 322/2001 [00:02<00:10, 160.87it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 403/2001 [00:02<00:09, 161.13it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 484/2001 [00:03<00:09, 161.33it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 565/2001 [00:03<00:08, 161.41it/s]Shapley Value Sampling attribution:  32%|‚ñà‚ñà‚ñà‚ñè      | 646/2001 [00:04<00:08, 161.51it/s]Shapley Value Sampling attribution:  36%|‚ñà‚ñà‚ñà‚ñã      | 727/2001 [00:04<00:07, 161.52it/s]Shapley Value Sampling attribution:  40%|‚ñà‚ñà‚ñà‚ñà      | 808/2001 [00:05<00:07, 161.59it/s]Shapley Value Sampling attribution:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 889/2001 [00:05<00:06, 161.57it/s]Shapley Value Sampling attribution:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 970/2001 [00:06<00:06, 161.62it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1051/2001 [00:06<00:05, 161.60it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1132/2001 [00:07<00:05, 161.64it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1213/2001 [00:07<00:04, 161.60it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1294/2001 [00:08<00:04, 161.63it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1375/2001 [00:08<00:03, 161.58it/s]Shapley Value Sampling attribution:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1456/2001 [00:09<00:03, 161.58it/s]Shapley Value Sampling attribution:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1537/2001 [00:09<00:02, 161.57it/s]Shapley Value Sampling attribution:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1618/2001 [00:10<00:02, 161.62it/s]Shapley Value Sampling attribution:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1699/2001 [00:10<00:01, 161.61it/s]Shapley Value Sampling attribution:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1780/2001 [00:11<00:01, 161.65it/s]Shapley Value Sampling attribution:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1861/2001 [00:11<00:00, 161.63it/s]Shapley Value Sampling attribution:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1942/2001 [00:12<00:00, 161.59it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 161.35it/s]
Trial 29: Average Relative Change in Mean Local SHAP Explanations = 0.966707 cosine sim: 0.9982554611164948
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.774680495262146, train_loss: 0.7901059985160828
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.25367072224617004, train_loss: 0.2299956977367401
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2314678132534027, train_loss: 0.17799749970436096
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.23233544826507568, train_loss: 0.17305707931518555
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2329101413488388, train_loss: 0.16415797173976898
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6746792197227478, train_loss: 0.6783751845359802
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.23341727256774902, train_loss: 0.19183456897735596
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2189110368490219, train_loss: 0.14760638773441315
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.21900881826877594, train_loss: 0.14410142600536346
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.21919091045856476, train_loss: 0.1388414353132248
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5690420269966125, train_loss: 0.5820673108100891
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.29952263832092285, train_loss: 0.20733629167079926
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2996447682380676, train_loss: 0.19212357699871063
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30108195543289185, train_loss: 0.18714074790477753
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3027867376804352, train_loss: 0.1784287989139557
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.635656476020813, train_loss: 0.662067711353302
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.20355118811130524, train_loss: 0.19216494262218475
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.18260429799556732, train_loss: 0.1431780308485031
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.18230971693992615, train_loss: 0.13663357496261597
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.1821349859237671, train_loss: 0.13014529645442963
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.22739705443382263, train_loss: 0.29942795634269714
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.07557358592748642, train_loss: 0.05840737000107765
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.07388473302125931, train_loss: 0.05089329183101654
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.07390031218528748, train_loss: 0.050197821110486984
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.07388380914926529, train_loss: 0.04914340004324913
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2869618237018585, train_loss: 0.37163570523262024
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.0699848011136055, train_loss: 0.04833581671118736
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.06490235030651093, train_loss: 0.03734767809510231
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.06482110917568207, train_loss: 0.0358516126871109
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.0646379366517067, train_loss: 0.033730898052453995
Trial 30/30 - Computing SHAP values
Shapley Value Sampling attribution:   0%|          | 0/2001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   4%|‚ñç         | 78/2001 [00:00<00:12, 154.81it/s]Shapley Value Sampling attribution:   8%|‚ñä         | 160/2001 [00:01<00:11, 160.07it/s]Shapley Value Sampling attribution:  12%|‚ñà‚ñè        | 242/2001 [00:01<00:10, 161.75it/s]Shapley Value Sampling attribution:  16%|‚ñà‚ñå        | 324/2001 [00:02<00:10, 162.39it/s]Shapley Value Sampling attribution:  20%|‚ñà‚ñà        | 406/2001 [00:02<00:09, 162.73it/s]Shapley Value Sampling attribution:  24%|‚ñà‚ñà‚ñç       | 488/2001 [00:03<00:09, 162.95it/s]Shapley Value Sampling attribution:  28%|‚ñà‚ñà‚ñä       | 570/2001 [00:03<00:08, 163.06it/s]Shapley Value Sampling attribution:  33%|‚ñà‚ñà‚ñà‚ñé      | 652/2001 [00:04<00:08, 163.00it/s]Shapley Value Sampling attribution:  37%|‚ñà‚ñà‚ñà‚ñã      | 734/2001 [00:04<00:07, 163.13it/s]Shapley Value Sampling attribution:  41%|‚ñà‚ñà‚ñà‚ñà      | 816/2001 [00:05<00:07, 163.20it/s]Shapley Value Sampling attribution:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 898/2001 [00:05<00:06, 163.24it/s]Shapley Value Sampling attribution:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 980/2001 [00:06<00:06, 163.25it/s]Shapley Value Sampling attribution:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1062/2001 [00:06<00:05, 163.28it/s]Shapley Value Sampling attribution:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1144/2001 [00:07<00:05, 163.29it/s]Shapley Value Sampling attribution:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1226/2001 [00:07<00:04, 163.31it/s]Shapley Value Sampling attribution:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1308/2001 [00:08<00:04, 163.35it/s]Shapley Value Sampling attribution:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1390/2001 [00:08<00:03, 163.38it/s]Shapley Value Sampling attribution:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1472/2001 [00:09<00:03, 163.39it/s]Shapley Value Sampling attribution:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1554/2001 [00:09<00:02, 163.37it/s]Shapley Value Sampling attribution:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1636/2001 [00:10<00:02, 163.37it/s]Shapley Value Sampling attribution:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1718/2001 [00:10<00:01, 163.39it/s]Shapley Value Sampling attribution:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1800/2001 [00:11<00:01, 163.41it/s]Shapley Value Sampling attribution:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1882/2001 [00:11<00:00, 163.39it/s]Shapley Value Sampling attribution:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1964/2001 [00:12<00:00, 163.38it/s]Shapley Value Sampling attribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2001/2001 [00:12<00:00, 163.02it/s]
Trial 30: Average Relative Change in Mean Local SHAP Explanations = 0.936299 cosine sim: 0.9982447358785965
SHAP computation completed. Results saved to: results/sprint/shapley
JSON summary written to: results/sprint/shapley/sprint_shap_summary_False.json

Top 15 features by mean absolute SHAP value:
  1. age
  2. egfr
  3. dbp
  4. screat
  5. chr
  6. sub_ckd
  7. n_agents
  8. sbp
  9. hdl
  10. female
  11. bmi
  12. glur
  13. smoke_3cat
  14. race_black
  15. sub_cvd
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mvivid-universe-6[0m at: [34mhttps://wandb.ai/data_att/Convergence%20for%20Shapley%20value%20sprint/runs/mcc8zefi[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../../data/mingyulu/wandb/wandb/run-20260203_174833-mcc8zefi/logs[0m
